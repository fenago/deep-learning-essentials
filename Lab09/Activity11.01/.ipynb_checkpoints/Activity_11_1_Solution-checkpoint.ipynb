{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "303iHntmdiDj"
   },
   "source": [
    "# **Activity 11.1 Generate Images with DCGAN**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8_-1h5ddiDp",
    "outputId": "6179818c-3d20-493a-aa13-fe9147b4256f"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUutWi1Anz54"
   },
   "source": [
    "## **Import needed libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KubxTY1mdiDm"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import InputLayer, Reshape, Dropout, Dense \n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xq4WgFjs6GtV"
   },
   "outputs": [],
   "source": [
    "def time_string(sec_elapsed):\n",
    "    hour = int(sec_elapsed / (60 * 60))\n",
    "    minute = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    second = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(hour, minute, second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dFBMQjeoPlg"
   },
   "source": [
    "## **Resolution, channels, preview rows and columns, SEED, DATA PATH, EPOCH, BATCH SIZE, BUFFER SIZE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tb_XblE7diDr",
    "outputId": "188a6632-5484-4875-c660-ccc739f45965"
   },
   "outputs": [],
   "source": [
    "gen_res = 3 \n",
    "gen_square = 32 * gen_res\n",
    "img_chan = 3\n",
    "img_rows = 5\n",
    "img_cols = 5\n",
    "img_margin = 16\n",
    "seed_vector = 200\n",
    "data_path = 'banana-or-orange/training_set/'\n",
    "epochs = 500\n",
    "num_batch = 32\n",
    "num_buffer = 60000\n",
    "\n",
    "print(f\"Will generate a resolution of {gen_res}.\")\n",
    "print(f\"Will generate {gen_square}px square images.\")\n",
    "print(f\"Will generate {img_chan} image channels.\")\n",
    "print(f\"Will generate {img_rows} preview rows.\")\n",
    "print(f\"Will generate {img_cols} preview columns.\")\n",
    "print(f\"Our preview margin equals {img_margin}.\")\n",
    "print(f\"Our data path is: {data_path}.\")\n",
    "print(f\"Our number of epochs are: {epochs}.\")\n",
    "print(f\"Will generate a batch size of {num_batch}.\")\n",
    "print(f\"Will generate a buffer size of {num_buffer}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dJ69ALfSdiDv",
    "outputId": "ccf7cee7-d7e1-452f-b799-af3e53f25f4e"
   },
   "outputs": [],
   "source": [
    "training_binary_path = os.path.join(data_path,\n",
    "                                    f'training_data_{gen_square}_{gen_square}.npy')\n",
    "\n",
    "print(f\"Looking for file: {training_binary_path}\")\n",
    "\n",
    "if not os.path.isfile(training_binary_path):\n",
    "    start = time.time()\n",
    "    print(\"Loading training images...\")\n",
    "\n",
    "    train_data = []\n",
    "    images_path = os.path.join(data_path,'banana')\n",
    "    for filename in tqdm(os.listdir(images_path)):\n",
    "        path = os.path.join(images_path,filename)\n",
    "        images = Image.open(path).resize((gen_square,\n",
    "            gen_square),Image.ANTIALIAS)\n",
    "        train_data.append(np.asarray(images))\n",
    "    train_data = np.reshape(train_data,(-1,gen_square,\n",
    "              gen_square,img_chan))\n",
    "    train_data = train_data.astype(np.float32)\n",
    "    train_data = train_data / 127.5 - 1.\n",
    "\n",
    "    print(\"Saving training image binary...\")\n",
    "    np.save(training_binary_path,train_data)\n",
    "    elapsed = time.time()-start\n",
    "    print (f'Image preprocess time: {time_string(elapsed)}')\n",
    "else:\n",
    "    print(\"Loading training data...\")\n",
    "    train_data = np.load(training_binary_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXl0JohJBx69"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_data) \\\n",
    "    .shuffle(num_buffer).batch(num_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Uc9clhao7ua"
   },
   "source": [
    "## **Build the Generator and Discrminator for the DCGAN and vanilla GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ulou-BZPybzT"
   },
   "outputs": [],
   "source": [
    "def create_dc_generator(seed_size, channels):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(4*4*256,activation=\"relu\",input_dim=seed_size))\n",
    "    model.add(Reshape((4,4,256)))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "   \n",
    "    # Output resolution, additional upsampling\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    if gen_res>1:\n",
    "        model.add(UpSampling2D(size=(gen_res,gen_res)))\n",
    "        model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "    # Final CNN layer\n",
    "    model.add(Conv2D(channels,kernel_size=3,padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_dc_discriminator(image_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=image_shape, \n",
    "                     padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_generator(seed_size, channels):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(96*96*3,activation=\"tanh\",input_dim=seed_size))\n",
    "    model.add(Reshape((96,96,3)))\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_discriminator(img_size):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=img_size))\n",
    "    model.add(Dense(1024, activation=\"tanh\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKnCeDut2cp0"
   },
   "outputs": [],
   "source": [
    "def save_images(generator, cnt, noise, prefix=None):\n",
    "    img_array = np.full(( \n",
    "      img_margin + (img_rows * (gen_square+img_margin)), \n",
    "      img_margin + (img_cols * (gen_square+img_margin)), 3), \n",
    "      255, dtype=np.uint8)\n",
    "  \n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    img_count = 0\n",
    "    for row in range(img_rows):\n",
    "        for col in range(img_cols):\n",
    "            r = row * (gen_square+16) + img_margin\n",
    "            c = col * (gen_square+16) + img_margin\n",
    "            img_array[r:r+gen_square,c:c+gen_square] \\\n",
    "                = gen_imgs[img_count] * 255\n",
    "            img_count += 1\n",
    "\n",
    "          \n",
    "    output_path = os.path.join(data_path,'output')\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "  \n",
    "    filename = os.path.join(output_path,f\"train{prefix}-{cnt}.png\")\n",
    "    im = Image.fromarray(img_array)\n",
    "    im.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "gL5byGhNzOzd",
    "outputId": "d821b525-9819-4d7a-b594-b8743a7b8427"
   },
   "outputs": [],
   "source": [
    "dc_generator = create_dc_generator(seed_vector, img_chan)\n",
    "\n",
    "noise = tf.random.normal([1, seed_vector])\n",
    "gen_img = dc_generator(noise, training=False)\n",
    "\n",
    "plt.imshow(gen_img[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = create_generator(seed_vector, img_chan)\n",
    "gen_van_img = generator(noise, training=False)\n",
    "plt.imshow(gen_van_img[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LOnTxIXnyeEQ",
    "outputId": "1be9ea6c-6cdd-43bf-c017-2335e82dfb68"
   },
   "outputs": [],
   "source": [
    "img_shape = (gen_square,gen_square,img_chan)\n",
    "\n",
    "dc_discriminator = create_dc_discriminator(img_shape)\n",
    "dc_decision = dc_discriminator(gen_img)\n",
    "print(dc_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = create_discriminator(img_shape)\n",
    "decision = discriminator(gen_img)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBaP98zAySJV"
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def discrim_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def gen_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79UDhOCa0R4h"
   },
   "outputs": [],
   "source": [
    "gen_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)\n",
    "disc_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzyh-LqU0j5d"
   },
   "outputs": [],
   "source": [
    "def train_step(generator, discriminator, images):\n",
    "    seed = tf.random.normal([num_batch, seed_vector])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_imgs = generator(seed, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(gen_imgs, training=True)\n",
    "\n",
    "        g_loss = gen_loss(fake_output)\n",
    "        d_loss = discrim_loss(real_output, fake_output)\n",
    "\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(\\\n",
    "            g_loss, generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(\\\n",
    "            d_loss, discriminator.trainable_variables)\n",
    "\n",
    "        gen_optimizer.apply_gradients(zip(\n",
    "            gradients_of_generator, generator.trainable_variables))\n",
    "        disc_optimizer.apply_gradients(zip(\n",
    "            gradients_of_discriminator, \n",
    "            discriminator.trainable_variables))\n",
    "    return g_loss,d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NjrRgDR10lSF"
   },
   "outputs": [],
   "source": [
    "def train(generator, discriminator, dataset, epochs, prefix=None):\n",
    "    fixed_seed = np.random.normal(0, 1, (img_rows * img_cols, \n",
    "                                       seed_vector))\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        g_loss_list = []\n",
    "        d_loss_list = []\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            t = train_step(generator, discriminator, image_batch)\n",
    "            g_loss_list.append(t[0])\n",
    "            d_loss_list.append(t[1])\n",
    "\n",
    "        generator_loss = sum(g_loss_list) / len(g_loss_list)\n",
    "        discriminator_loss = sum(d_loss_list) / len(d_loss_list)\n",
    "\n",
    "        epoch_elapsed = time.time()-epoch_start\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print (f'Epoch {epoch+1}, gen loss={generator_loss},disc loss={discriminator_loss},'\\\n",
    "               f' {time_string(epoch_elapsed)}')\n",
    "            save_images(generator, epoch,fixed_seed, prefix=prefix)\n",
    "\n",
    "    elapsed = time.time()-start\n",
    "    print (f'Training time: {time_string(elapsed)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vWmEHprD0t1V",
    "outputId": "6757b93a-00bf-4bcc-ea3a-e9f143f12031"
   },
   "outputs": [],
   "source": [
    "train(dc_generator, dc_discriminator, train_dataset, epochs, prefix='-dc-gan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "jprrfMKpB0Dz",
    "outputId": "750fab4a-4732-41ba-a71c-2f30690e92c8"
   },
   "outputs": [],
   "source": [
    "train(generator, discriminator, train_dataset, epochs, prefix='-vanilla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "eGi6_OGm6nDr",
    "outputId": "99a50b82-7244-4c34-d8ff-16918fced35b"
   },
   "outputs": [],
   "source": [
    "dcgan_99 = imread('banana-or-orange/training_set/output/train-dc-gan-99.png')\n",
    "plt.imshow(dcgan_499)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "Ciz8wwXg6nbS",
    "outputId": "88d04fe3-66e1-49b2-9a0b-33cf449b1d04"
   },
   "outputs": [],
   "source": [
    "dcgan_499 = imread('banana-or-orange/training_set/output/train-dc-gan-499.png')\n",
    "plt.imshow(dcgan_499)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "id": "ypMzdlUd8W_H",
    "outputId": "98511011-016d-470d-8ebe-f2620fb4706d"
   },
   "outputs": [],
   "source": [
    "vanilla_99 = imread('banana-or-orange/training_set/output/train-vanilla-99.png')\n",
    "plt.imshow(vanilla_499)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15Hia_feD9sm"
   },
   "outputs": [],
   "source": [
    "vanilla_499 = imread('banana-or-orange/training_set/output/train-vanilla-499.png')\n",
    "plt.imshow(vanilla_499)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Activity 11.1 Solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
